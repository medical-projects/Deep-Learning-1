# -*- coding: utf-8 -*-
"""CNN_FIRE_600_Images.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Or4_yyEkpg5CI70TmETorcSooBAcFIFH
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import regularizers
from tensorflow.keras.models import Sequential,Model

from tensorflow.keras.layers import Conv2D,MaxPooling2D,AveragePooling2D,ZeroPadding2D
from tensorflow.keras.layers import Input,Flatten,Dense,Dropout,BatchNormalization
from tensorflow.keras.layers import Concatenate
from tensorflow.keras.optimizers import Adam,SGD

import glob
fire=glob.glob("/home/hemanth/Documents/Machine_Learning_Task/Data/Fire/*.*")
neutral=glob.glob("/home/hemanth/Documents/Machine_Learning_Task/Data/Neutral/*.*")
smoke=glob.glob("/home/hemanth/Documents/Machine_Learning_Task/Data/Smoke/*.*")

data=[]
labels=[]

for i in fire:
    image=tf.keras.preprocessing.image.load_img(i,color_mode='rgb',target_size=(224,224))
    image=np.array(image)
    data.append(image)
    labels.append(0)

for i in neutral:
    image=tf.keras.preprocessing.image.load_img(i,color_mode='rgb',target_size=(224,224))
    image=np.array(image)
    data.append(image)
    labels.append(0)

for i in smoke:
    image=tf.keras.preprocessing.image.load_img(i,color_mode='rgb',target_size=(224,224))
    image=np.array(image)
    data.append(image)
    labels.append(0)

data=np.array(data)
labels=np.array(labels)

print(data.shape)
print(labels.shape)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(data,labels,test_size=0.4,random_state=42)

x_valid,x_test,y_valid,y_test=train_test_split(x_test,y_test,test_size=0.5,random_state=42)

x_train=x_train/255
x_test=x_test/255
x_valid=x_valid/255

print("Training set: ",x_train.shape)
print("Validation set: ",x_valid.shape)
print("Testing set: ",x_test.shape)

num_classes = 3
input_shape = (224,224, 3)
kernel = (3, 3)

# fix random seed for reproducibility 
seed = 101
np.random.seed(seed)

import keras
from keras.constraints import maxnorm
model = Sequential()
model.add(Conv2D(64, kernel_size=kernel, activation='relu', input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128, kernel_size=kernel, activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
#model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

model.summary()

BATCH_SIZE = 16
EPOCH_STEPS = int(x_train.shape[0]/BATCH_SIZE)
MODEL_NAME = 'cnn_fire_dataset.h5'

model.compile(loss="sparse_categorical_crossentropy", optimizer='adam', metrics=['accuracy'])

history = model.fit(x_train,y_train,epochs=5,steps_per_epoch=EPOCH_STEPS,validation_data=(x_valid,y_valid))

model.save(MODEL_NAME)

score = model.evaluate(x_test, y_test)
print('Score:', score[1])

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

import pandas as pd
d=pd.DataFrame({"Accuracy_CNN_600images":history.history["accuracy"],
               "validation_Accuracy_CNN_600Images":history.history["val_accuracy"],
                "loss_CNN_600Images":history.history["loss"],
                "validation_loss_CNN_600Images":history.history["val_loss"]
                
               })

d

